{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚õèÔ∏è App Icon - Embedding\n",
    "\n",
    "Use a pretrained VGG model to embed the style and content of app icons into feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "from keras.applications                         import VGG19\n",
    "from tensorflow.keras.preprocessing.image       import load_img, img_to_array\n",
    "from keras.applications.vgg19                   import preprocess_input\n",
    "from keras.applications.vgg19                   import decode_predictions\n",
    "from tensorflow.keras.models                    import Model\n",
    "from sklearn.random_projection                  import SparseRandomProjection\n",
    "from   PIL                                      import Image\n",
    "from   tqdm                                     import tqdm\n",
    "import pandas                                   as pd\n",
    "import numpy                                    as np\n",
    "import sys, os, ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TQDM library for Pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° START ‚ö°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-Truth Dataset\n",
    "#INPUT_PATH  = \"../../../../0_Data/CSV/0_AndroCatSet.csv\"\n",
    "INPUT_PATH  = \"../../../../0_Data/CSV/1_AndroCatSet_MiniTEST.csv\"\n",
    "\n",
    "# Output Path\n",
    "OUTPUT_PATH = \"../TMP/4e_AppIconFeatures.csv\"\n",
    "\n",
    "TMP_PATH = \"../TMP/\"\n",
    "if not os.path.exists(TMP_PATH):\n",
    "    os.makedirs(TMP_PATH)\n",
    "    print(\"üìÅüÜï Folder created       :\", TMP_PATH)\n",
    "else:\n",
    "    print(\"üìÅ‚úÖ Folder already exists:\", TMP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 151836"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF = pd.read_csv(INPUT_PATH, index_col=False)\n",
    "print(\"#Ô∏è‚É£ Apps: {}\".format(appsDF.shape[0]))\n",
    "\n",
    "appsDF.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess Icons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICONS_PATH  = \"../TMP/appIcons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess images for VGG Input\n",
    "def preprocessImg(sha256, iconsPath):\n",
    "\n",
    "    # Get the icon path\n",
    "    iconPath = iconsPath + sha256 + \".png\"\n",
    "\n",
    "    img = Image.open(iconPath).convert(\"RGB\")  # Convert image to RGBA format\n",
    "    img = img.resize((224, 224))  # Resize the image\n",
    "    x = img_to_array(img)\n",
    "    x = preprocess_input(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚õèÔ∏è Preprocess Images\")\n",
    "appsDF['imageFeatures'] = appsDF['sha256'].progress_apply(lambda x: preprocessImg(x, ICONS_PATH))\n",
    "\n",
    "print(\"\\nüìê Tensor Shape: {}\".format(appsDF.loc[0,'imageFeatures'].shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the VGG pretained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pre-trained VGG19 model\n",
    "vggModel = VGG19(weights='imagenet', include_top=True)\n",
    "\n",
    "# Get all the layers with their names\n",
    "for i, layer in enumerate(vggModel.layers):\n",
    "    print(\"Layer {}: {}\".format(i,layer.name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Content Embedding - VGG19 (fc_2 layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a modified model that includes only the layers up to and including the desired layer\n",
    "def getModifiedModel(model,desiredOutputLayer):\n",
    "    outputs = [layer.output for layer in model.layers[:desiredOutputLayer + 1]]\n",
    "    modifieModel = Model(inputs=model.input, outputs=outputs)\n",
    "    return modifieModel\n",
    "\n",
    "# Get the output of the last layer\n",
    "def getVggEmbedding(X, model):\n",
    "    # Use VGG to extract output of last layer\n",
    "    Y = model.predict(X, verbose=  0)[-1]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want the output from fc_2 layer (24)\n",
    "contentVggModel = getModifiedModel(vggModel, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚õèÔ∏è VGG19 fc_2 layer Extraction\")\n",
    "appsDF['contentEmbedding'] = appsDF['imageFeatures'].progress_apply(lambda x: getVggEmbedding(x, contentVggModel))\n",
    "\n",
    "print(\"\\n‚õèÔ∏è Reshape\")\n",
    "appsDF['contentEmbedding'] = appsDF['contentEmbedding'].progress_apply(lambda x: np.reshape(x, 4096))\n",
    "\n",
    "print(\"\\nüìê Tensor Shape: {}\".format(appsDF.loc[0,'contentEmbedding'].shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop image features\n",
    "appsDF = appsDF.drop('imageFeatures', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚õèÔ∏è 6) Reorganizing features as lists\")\n",
    "appsDF['contentEmbedding'] = appsDF['contentEmbedding'].progress_apply(lambda x: x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "appsDF.to_csv(OUTPUT_PATH, index=False)\n",
    "appsDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîö END \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
