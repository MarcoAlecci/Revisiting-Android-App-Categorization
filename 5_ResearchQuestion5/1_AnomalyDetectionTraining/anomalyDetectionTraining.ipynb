{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚õèÔ∏è RQ5 - Malicious Dataset - Restricted APIs - Training Benign Apps Only (4500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT\n",
    "from    sklearn.feature_extraction.text     import TfidfVectorizer\n",
    "from    sklearn.feature_extraction.text     import CountVectorizer\n",
    "from    tqdm                                import tqdm\n",
    "from    sklearn.svm                         import OneClassSVM\n",
    "from    joblib                              import dump, load\n",
    "import  pandas                              as pd\n",
    "import  numpy                               as np\n",
    "import  ast\n",
    "import  os\n",
    "import  shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TQDM library for Pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° START ‚ö°\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED PATHS\n",
    "INPUT_PATH  = \"../../0_Data/CSV/RQ5/5_AndroCatSetClusteringLabels.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Seed for Reproducibility.\n",
    "RANDOM_SEED = 151836"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF = pd.read_csv(INPUT_PATH, index_col=False)\n",
    "print(\"#Ô∏è‚É£ Apps: {}\".format(appsDF.shape[0]))\n",
    "\n",
    "appsDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüî® 1. Reading data as lists\")\n",
    "appsDF['apisList'] = appsDF['apisList'].progress_apply(ast.literal_eval) \n",
    "\n",
    "print(\"\\nüî® 2. Order the lists\")\n",
    "appsDF['apisList'] = appsDF['apisList'].progress_apply(lambda lst: sorted(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add malicious apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maliciousDF =  pd.read_csv(\"../../0_Data/CSV/RQ5/5_MaliciousDatasetClusteringLabels.csv\", index_col=False)\n",
    "print(\"#Ô∏è‚É£ Malicious Apps: {}\".format(maliciousDF.shape[0]))\n",
    "\n",
    "print(\"\\nüî® 1. Reading data as lists\")\n",
    "maliciousDF['apisList'] = maliciousDF['apisList'].progress_apply(ast.literal_eval) \n",
    "\n",
    "print(\"\\nüî® 2. Order the lists\")\n",
    "maliciousDF['apisList'] = maliciousDF['apisList'].progress_apply(lambda lst: sorted(lst))\n",
    "\n",
    "maliciousDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sample 500 malicious apps\n",
    "maliciousDF = maliciousDF.sample(n=500, random_state = RANDOM_SEED)\n",
    "print(\"#Ô∏è‚É£ Malicious Apps: {}\".format(maliciousDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating vertically\n",
    "appsDF = pd.concat([appsDF, maliciousDF], ignore_index=True)\n",
    "appsDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Embedding Restricted API as Binary Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CountVectorizer to transform the lists into feature vectors\n",
    "vectorizer = CountVectorizer(binary=True, tokenizer=lambda x: x.split('&&&'),token_pattern=None)\n",
    "\n",
    "# Store daata in the DF as numpy arrays\n",
    "appsDF['features'] = list(vectorizer.fit_transform(appsDF['apisList'].apply('&&&'.join)).toarray())\n",
    "\n",
    "print(\"üìê Len features: {}\".format(len(appsDF['features'][0])))\n",
    "\n",
    "appsDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Split into Training Set and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF = appsDF[appsDF['isMalicious'] == False]\n",
    "print(\"#Ô∏è‚É£   APPS: {}\".format(appsDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF = pd.DataFrame()\n",
    "testDF     = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 5000, 100):\n",
    "\n",
    "    trainingRows = appsDF.iloc[i:i+90]\n",
    "    testRows     = appsDF.iloc[i+90:i+100]\n",
    "\n",
    "    # Concatenate the two DataFrames horizontally\n",
    "    trainingDF = pd.concat([trainingDF, trainingRows], ignore_index=True)\n",
    "    testDF = pd.concat([testDF, testRows], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(folderPath):\n",
    "    if not os.path.exists(folderPath):\n",
    "        os.makedirs(folderPath)\n",
    "\n",
    "def deleteFolder(folderPath):\n",
    "    shutil.rmtree(folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save Model\n",
    "MODEL_PATH = \"../TMP/Models/\"\n",
    "APPROACHES = [\"Chabada\", \"Gcata\"]\n",
    "\n",
    "for appr in APPROACHES:\n",
    "    createFolder(MODEL_PATH + \"{}/\".format(appr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingGroupedByCluster(trainingDF, columnName):\n",
    "\n",
    "    print(\"\\nüè∑Ô∏è Approach: {}\".format(columnName))\n",
    "\n",
    "    # To keep track of the total\n",
    "    totalOutliers = 0\n",
    "\n",
    "    # For each category train a model\n",
    "    for classID, typeDF in trainingDF.groupby(columnName):\n",
    "\n",
    "        #print(\"\\nüè∑Ô∏è Training          : {}\".format(classID))\n",
    "        \n",
    "        # Get the features as a list\n",
    "        X = np.stack(typeDF['features'].values)\n",
    "        #print(\"#Ô∏è‚É£ Num apps          : {}\".format(len(X)))\n",
    "\n",
    "        #Create and fit\n",
    "        model = OneClassSVM(    kernel='rbf',\n",
    "                                gamma=0.0005,\n",
    "                                cache_size=100,\n",
    "                                tol=0.0001,       \n",
    "                                nu=0.01,\n",
    "                                shrinking = True\n",
    "                            ).fit(X)\n",
    "        \n",
    "\n",
    "        # Dump the model\n",
    "        dump(model, MODEL_PATH + '{}/OCSVM_{}.joblib'.format(columnName, int(classID)))\n",
    "\n",
    "        # Print statistics about training\n",
    "        Y = model.predict(X)\n",
    "        numOutliers = np.count_nonzero(Y == -1)\n",
    "        #print(\"‚ö†Ô∏è Training Outliers : {} ({:.0%})\".format(numOutliers,numOutliers/len(Y)))\n",
    "\n",
    "        # Update the total number of outliers\n",
    "        totalOutliers += numOutliers\n",
    "\n",
    "    # Print the total number of outliers\n",
    "    print(\"#Ô∏è‚É£ Outliers: {} ({:.2%})\".format(totalOutliers, totalOutliers / trainingDF.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü¶æ TRAINING\")\n",
    "\n",
    "for approach in APPROACHES:\n",
    "    trainingGroupedByCluster(trainingDF, approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîö END \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
