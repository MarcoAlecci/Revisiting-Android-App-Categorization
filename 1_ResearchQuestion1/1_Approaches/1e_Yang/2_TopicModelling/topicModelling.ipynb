{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚õèÔ∏è YANG - TopicModelling\n",
    "\n",
    "This notebook uses LDA (Latent Dirichlet Allocation) to extract the topics from each app description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "from    sklearn.metrics                    import adjusted_rand_score\n",
    "from    sklearn.feature_extraction.text    import CountVectorizer\n",
    "from    tqdm                               import tqdm\n",
    "import  pandas                             as pd\n",
    "import  lda\n",
    "import  os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TQDM library for Pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° START ‚ö°\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-Truth Dataset\n",
    "INPUT_PATH  = \"../TMP/1e_YangPreprocessedDescriptions.csv\"\n",
    "\n",
    "# Output Path\n",
    "OUTPUT_PATH = \"../1e_YangClusteringLabels.csv\"\n",
    "\n",
    "TMP_PATH = \"../TMP\"\n",
    "if not os.path.exists(TMP_PATH):\n",
    "    os.makedirs(TMP_PATH)\n",
    "    print(\"üìÅüÜï Folder created       :\", TMP_PATH)\n",
    "else:\n",
    "    print(\"üìÅ‚úÖ Folder already exists:\", TMP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 151836"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF = pd.read_csv(INPUT_PATH, index_col=False)\n",
    "print(\"#Ô∏è‚É£ Apps: {}\".format(appsDF.shape[0]))\n",
    "\n",
    "appsDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Vectorize using CountVEctorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus\n",
    "corpus = []\n",
    "for description in appsDF['preprocessedDescription']:\n",
    "    corpus.append(description)\n",
    "\n",
    "# Vectorize\n",
    "vectorizer = CountVectorizer(stop_words='english', strip_accents='ascii', dtype='int32')\n",
    "tfArray    = vectorizer.fit_transform(corpus).toarray()\n",
    "vocabolary = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getARIscore(clusteringLabels):\n",
    "    ariScore = adjusted_rand_score(appsDF[\"classID\"].values, clusteringLabels)\n",
    "    print(\"üéØ ARI: {:.4f}\".format(ariScore))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "NUM_TOPICS  = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and fit LDA\n",
    "model = lda.LDA(n_topics = NUM_TOPICS, n_iter=100, random_state = RANDOM_SEED)\n",
    "model.fit(tfArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the labels\n",
    "clusteringLabels = [] \n",
    "docTopics = model.doc_topic_\n",
    "for i in range(appsDF.shape[0]):\n",
    "     clusteringLabels.append(docTopics[i].argmax())\n",
    "\n",
    "print(\"\\n‚≠ê LDA\")\n",
    "getARIscore(clusteringLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the labels into the Pandas DF\n",
    "appsDF = appsDF.loc[:, ['sha256']]\n",
    "appsDF['clusterID'] = clusteringLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "appsDF.to_csv(OUTPUT_PATH,index=False)\n",
    "appsDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîö END \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
