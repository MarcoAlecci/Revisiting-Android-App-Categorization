{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚õèÔ∏è REACT - Topic Modelling\n",
    "\n",
    "Notebook for performing topic modeling using Latent Dirichlet Allocation (MALLET) to extract the topics of each app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "from   pandas.core.common   import flatten\n",
    "from   tqdm                 import tqdm\n",
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "import subprocess\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TQDM library for Pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° START ‚ö°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-Truth Dataset\n",
    "INPUT_PATH  = \"../TMP/1a_ReactDataPreprocessed.csv\"\n",
    "\n",
    "# Output Path\n",
    "OUTPUT_PATH = \"../TMP/1a_ReactTopics.csv\"\n",
    "\n",
    "TMP_PATH = \"../TMP\"\n",
    "if not os.path.exists(TMP_PATH):\n",
    "    os.makedirs(TMP_PATH)\n",
    "    print(\"üìÅüÜï Folder created       :\", TMP_PATH)\n",
    "else:\n",
    "    print(\"üìÅ‚úÖ Folder already exists:\", TMP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF = pd.read_csv(INPUT_PATH,index_col=False)\n",
    "print(\"#Ô∏è‚É£   APPS: {}\".format(appsDF.shape[0]))\n",
    "\n",
    "appsDF.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Merge the features in a unique column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = ['xmlValues','guiText','methodNamesText']\n",
    "\n",
    "print(\"\\nüî® 0. Loading data as lists\")\n",
    "for column in COLUMNS:\n",
    "    appsDF[column] = appsDF[column].progress_apply(ast.literal_eval)      \n",
    "\n",
    "def mergeColumns(sha256):\n",
    "    featuresList = []\n",
    "    for column in COLUMNS:\n",
    "        featuresList.append(appsDF.loc[appsDF['sha256'] == sha256,column])\n",
    "    return featuresList\n",
    "\n",
    "#  Merge columns\n",
    "print(\"\\nüî® 1. Merge Columns\")\n",
    "appsDF['features'] = appsDF['sha256'].progress_apply(mergeColumns)\n",
    "appsDF = appsDF.drop(COLUMNS,axis = 1)\n",
    "\n",
    "# Flatten\n",
    "print(\"\\nüî® 2. Flatten Columns\")\n",
    "appsDF['features'] = appsDF['features'].progress_apply(lambda x: list(flatten(x)))\n",
    "\n",
    "# To string\n",
    "print(\"\\nüî® 3. To string\")\n",
    "appsDF['features'] = appsDF['features'].progress_apply(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appsDF.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LDA Mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "NUM_TOPICS = 50\n",
    "TOPICS_MAX = 4\n",
    "TOPICS_TRESHOLD = 0.01\n",
    "\n",
    "MALLET_PATH          = \"/home/marco/Mallet/bin\"\n",
    "MALLET_INPUT_FOLDER  = \"./inputMallet\"\n",
    "MALLET_OUTPUT_FOLDER = \"./outputMallet\"\n",
    "MALLET_OUTPUT_FILE   = \"appsWithTopics.json\"\n",
    "\n",
    "binary_out_file  = \"topics_inf.mallet\"\n",
    "inferencer_file  = \"inferencer\"\n",
    "composition_file = \"composition.txt\"\n",
    "keywords_file    = \"keywords.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create output folder\n",
    "if not os.path.exists(MALLET_OUTPUT_FOLDER):\n",
    "    os.makedirs(MALLET_OUTPUT_FOLDER)\n",
    "\n",
    " # Create input folder\n",
    "if not os.path.exists(MALLET_INPUT_FOLDER):\n",
    "    os.makedirs(MALLET_INPUT_FOLDER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input\n",
    "with open(MALLET_INPUT_FOLDER + \"/input.txt\", 'w') as f:\n",
    "    for index, row in appsDF.iterrows():\n",
    "        f.write(row[\"sha256\"] + \"\\t\" + row[\"features\"] + \"\\n\")\n",
    "\n",
    "subprocess.call([\"{}/mallet\".format(MALLET_PATH),\n",
    "                \"import-file\",\n",
    "                \"--input\", MALLET_INPUT_FOLDER + \"/input.txt\",\n",
    "                \"--output\", os.path.join(MALLET_INPUT_FOLDER, binary_out_file),\n",
    "                \"--keep-sequence\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Modelling\n",
    "with open('train-topics-output.txt', 'w') as out_file:\n",
    "    subprocess.call([\"{}/mallet\".format(MALLET_PATH),\n",
    "                 \"train-topics\",\n",
    "                 \"--input\",                 os.path.join(MALLET_INPUT_FOLDER, binary_out_file),\n",
    "                 \"--num-topics\",            str(NUM_TOPICS),\n",
    "                 \"--output-topic-keys\",     os.path.join(MALLET_OUTPUT_FOLDER, keywords_file),\n",
    "                 \"--num-top-words\",         \"200\",\n",
    "                 \"--output-doc-topics\",     os.path.join(MALLET_OUTPUT_FOLDER, composition_file),\n",
    "                 \"--optimize-interval\",     \"10\",\n",
    "                 \"--doc-topics-max\",        str(TOPICS_MAX),\n",
    "                 \"--doc-topics-threshold\",  str(TOPICS_TRESHOLD),\n",
    "                 \"--inferencer-filename\",   os.path.join(MALLET_OUTPUT_FOLDER, inferencer_file)],\n",
    "                stdout=out_file, stderr=subprocess.STDOUT\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Save the composition file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the column names\n",
    "columnsNames = ['id','sha256']\n",
    "for i in range(1, 5):\n",
    "    columnsNames.extend(['topic{}'.format(i), 'probability{}'.format(i)])\n",
    "\n",
    "# Read and save the file\n",
    "compositionDF = pd.read_csv(os.path.join(MALLET_OUTPUT_FOLDER, composition_file), sep='\\t', skiprows=1, header=None, names=columnsNames + ['extra'])\n",
    "\n",
    "compositionDF\n",
    "compositionDF = compositionDF.iloc[:, 1:-1]\n",
    "\n",
    "# Cast topics to int\n",
    "compositionDF = compositionDF.fillna(-1)\n",
    "compositionDF = compositionDF.replace([np.inf, -np.inf], -1)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    compositionDF['topic{}'.format(i)] = compositionDF['topic{}'.format(i)].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the \"classID\" column as the second column in compositionDF\n",
    "compositionDF.insert(1, 'classID', appsDF['classID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "compositionDF.to_csv(OUTPUT_PATH,index=False)\n",
    "compositionDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîö END \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
